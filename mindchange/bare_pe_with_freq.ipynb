{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "folder_path = '../models/'\n",
    "if folder_path not in sys.path:\n",
    "    sys.path.append(folder_path)\n",
    "\n",
    "folder_path = '../data/'\n",
    "if folder_path not in sys.path:\n",
    "    sys.path.append(folder_path)\n",
    "\n",
    "from cnmp import CNMP\n",
    "\n",
    "from data_generators import *\n",
    "from positional_encoders import *\n",
    "from plotters import *\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "def get_free_gpu():\n",
    "    gpu_util = []\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        torch.cuda.set_device(i)  # Switch GPU\n",
    "#        gpu_util.append((i, torch.cuda.memory_stats()['reserved_bytes.all.current'] / (1024 ** 2)))\n",
    "        gpu_util.append((i, torch.cuda.utilization()))\n",
    "    gpu_util.sort(key=lambda x: x[1])\n",
    "    return gpu_util[0][0]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    available_gpu = get_free_gpu()\n",
    "    if available_gpu == 0:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda:{available_gpu}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(\"Device :\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([180, 1200, 1]), y_train shape: torch.Size([180, 1200, 1]), g_train shape: torch.Size([180, 1])\n",
      "x_test shape: torch.Size([20, 1200, 1]), y_test shape: torch.Size([20, 1200, 1]), g_test shape: torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "dx, dy, dg, dph, dpe = 1, 1, 1, 0, 27\n",
    "num_demos, num_test = 180, 20\n",
    "num_trajs = num_demos + num_test\n",
    "t_steps = 1200\n",
    "n_max, m_max = 100, 100\n",
    "max_freq=5\n",
    "\n",
    "trajectories, _, freqs = generate_cyclic_trajectories_with_random_cycles(num_trajs=num_trajs, max_freq=max_freq, freq=True)\n",
    "\n",
    "perm_ids = torch.randperm(num_trajs)\n",
    "train_ids, test_ids = perm_ids[:num_demos], perm_ids[num_demos:]\n",
    "\n",
    "all_x = torch.linspace(0, 1, t_steps).unsqueeze(-1).unsqueeze(0).repeat(num_trajs,1,1)\n",
    "\n",
    "x_train, x_test = all_x[train_ids], all_x[test_ids]\n",
    "y_train, y_test = trajectories[train_ids], trajectories[test_ids]\n",
    "g_train, g_test = freqs[train_ids]/max_freq, freqs[test_ids]/max_freq\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}, g_train shape: {g_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}, g_test shape: {g_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = generate_positional_encoding(t_steps, dpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bare:  34050\n",
      "PE:  40706\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "\n",
    "enc_dims = [128,128]\n",
    "dec_dims = [128,128]\n",
    "\n",
    "m0_ = CNMP(input_dim=dx+dg, output_dim=dy, n_max=n_max, m_max=m_max, encoder_hidden_dims=enc_dims, decoder_hidden_dims=dec_dims, batch_size=batch_size, device=device)\n",
    "opt0 = torch.optim.Adam(lr=3e-4, params=m0_.parameters())\n",
    "\n",
    "m1_ = CNMP(input_dim=dpe+dg, output_dim=dy, n_max=n_max, m_max=m_max, encoder_hidden_dims=enc_dims, decoder_hidden_dims=dec_dims, batch_size=batch_size, device=device)\n",
    "opt1 = torch.optim.Adam(lr=3e-4, params=m1_.parameters())\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in m0_.parameters())\n",
    "print('Bare: ', pytorch_total_params)\n",
    "pytorch_total_params = sum(p.numel() for p in m1_.parameters())\n",
    "print('PE: ', pytorch_total_params)\n",
    "\n",
    "if torch.__version__ >= \"2.0\":\n",
    "    m0, m1 = torch.compile(m0_), torch.compile(m1_)\n",
    "else:\n",
    "    m0, m1 = m0_, m1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs0 = torch.zeros((batch_size, n_max, dx+dg+dy), dtype=torch.float32, device=device)\n",
    "tar_x0 = torch.zeros((batch_size, m_max, dx+dg), dtype=torch.float32, device=device)\n",
    "\n",
    "obs1 = torch.zeros((batch_size, n_max, dpe+dg+dy), dtype=torch.float32, device=device)\n",
    "tar_x1 = torch.zeros((batch_size, m_max, dpe+dg), dtype=torch.float32, device=device)\n",
    "\n",
    "tar_y = torch.zeros((batch_size, m_max, dy), dtype=torch.float32, device=device)\n",
    "obs_mask = torch.zeros((batch_size, n_max), dtype=torch.bool, device=device)\n",
    "tar_mask = torch.zeros((batch_size, m_max), dtype=torch.bool, device=device)\n",
    "\n",
    "def prepare_masked_batch(t: list, traj_ids: list):\n",
    "    global obs0, tar_x0, obs1, tar_x1, tar_y, obs_mask, tar_mask\n",
    "    obs0.fill_(0)\n",
    "    tar_x0.fill_(0)\n",
    "    obs1.fill_(0)\n",
    "    tar_x1.fill_(0)\n",
    "    tar_y.fill_(0)\n",
    "    obs_mask.fill_(False)\n",
    "    tar_mask.fill_(False)\n",
    "\n",
    "    for i, traj_id in enumerate(traj_ids):\n",
    "        traj = t[traj_id]\n",
    "\n",
    "        n = torch.randint(1, n_max+1, (1,)).item()\n",
    "        m = torch.randint(1, m_max+1, (1,)).item()\n",
    "\n",
    "        permuted_ids = torch.randperm(t_steps)\n",
    "        n_ids = permuted_ids[:n]\n",
    "        m_ids = permuted_ids[n:n+m]\n",
    "\n",
    "        obs0[i, :n, :dx] = x_train[traj_id, n_ids]  # t\n",
    "        obs0[i, :n, dx:dx+dg] = g_train[traj_id]  # gamma\n",
    "        obs0[i, :n, dx+dg:] = traj[n_ids]  # SM(t)\n",
    "\n",
    "        obs1[i, :n, :dpe] = pe[n_ids]  # PE(t)\n",
    "        obs1[i, :n, dpe:dpe+dg] = g_train[traj_id]  # gamma\n",
    "        obs1[i, :n, dpe+dg:] = traj[n_ids]  # SM(t)\n",
    "\n",
    "        obs_mask[i, :n] = True\n",
    "        \n",
    "        tar_x0[i, :m, :dx] = x_train[traj_id, m_ids]\n",
    "        tar_x0[i, :m, dx:] = g_train[traj_id]\n",
    "        tar_x1[i, :m, :dpe] = pe[m_ids]\n",
    "        tar_x1[i, :m, dpe:] = g_train[traj_id]        \n",
    "        \n",
    "        tar_y[i, :m] = traj[m_ids]\n",
    "        tar_mask[i, :m] = True\n",
    "\n",
    "\n",
    "test_obs0 = torch.zeros((batch_size, n_max, dx+dg+dy), dtype=torch.float32, device=device)\n",
    "test_tar_x0 = torch.zeros((batch_size, t_steps, dx+dg), dtype=torch.float32, device=device)\n",
    "\n",
    "test_obs1 = torch.zeros((batch_size, n_max, dpe+dg+dy), dtype=torch.float32, device=device)\n",
    "test_tar_x1 = torch.zeros((batch_size, t_steps, dpe+dg), dtype=torch.float32, device=device)\n",
    "\n",
    "test_tar_y = torch.zeros((batch_size, t_steps, dy), dtype=torch.float32, device=device)\n",
    "test_obs_mask = torch.zeros((batch_size, n_max), dtype=torch.bool, device=device)\n",
    "last_obs_vals = torch.zeros((batch_size, n_max, dx), dtype=torch.int32, device=device)  # only for plotting\n",
    "\n",
    "def prepare_masked_test_batch(t: list, traj_ids: list, fixed_ind=None):\n",
    "    global test_obs0, test_tar_x0, test_obs1, test_tar_x1, test_tar_y, test_obs_mask, last_obs_vals\n",
    "    test_obs0.fill_(0)\n",
    "    test_tar_x0.fill_(0)\n",
    "    test_obs1.fill_(0)\n",
    "    test_tar_x1.fill_(0)\n",
    "    test_tar_y.fill_(0)\n",
    "    test_obs_mask.fill_(False)\n",
    "    last_obs_vals.fill_(0)\n",
    "\n",
    "    for i, traj_id in enumerate(traj_ids):\n",
    "        traj = t[traj_id]\n",
    "\n",
    "        # n = num_peaks #torch.randint(5, n_max, (1,)).item()\n",
    "        n = torch.randint(1, n_max+1, (1,)).item()\n",
    "\n",
    "        permuted_ids = torch.randperm(t_steps)\n",
    "        n_ids = permuted_ids[:n]\n",
    "        m_ids = torch.arange(t_steps)\n",
    "\n",
    "        if fixed_ind != None:\n",
    "            for p in range(n):\n",
    "                n_ids[p] = fixed_ind[i, p]\n",
    "            # n_ids[-1] = fixed_ind[i]\n",
    "\n",
    "        test_obs0[i, :n, :dx] = x_test[traj_id, n_ids]  # t\n",
    "        test_obs0[i, :n, dx:dx+dg] = g_test[traj_id]\n",
    "        test_obs0[i, :n, dx+dg:] = traj[n_ids]  # SM(t)\n",
    "\n",
    "        test_obs1[i, :n, :dpe] = pe[n_ids]  # PE(t)\n",
    "        test_obs1[i, :n, dpe:dpe+dg] = g_test[traj_id]\n",
    "        test_obs1[i, :n, dpe+dg:] = traj[n_ids]\n",
    "\n",
    "        last_obs_vals[i, :n] = n_ids.unsqueeze(-1)\n",
    "        test_obs_mask[i, :n] = True\n",
    "        \n",
    "        test_tar_x0[i, :, :dx] = x_test[traj_id, m_ids]\n",
    "        test_tar_x1[i, :, :dpe] = pe[m_ids]\n",
    "\n",
    "        test_tar_y[i] = traj[m_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New BARE best: 0.48137712478637695, PE best: 1000000\n",
      "New PE best: 0.48646414279937744, BARE best: 0.48137712478637695\n",
      "Epoch: 0, Losses: BARE: 0.0021184097396002876, PE: 0.002119637091954549\n",
      "Epoch: 500, Losses: BARE: 0.9623352640072512, PE: 0.7991376954995923\n",
      "New BARE best: 0.42449620366096497, PE best: 0.48646414279937744\n",
      "New PE best: 0.40366673469543457, BARE best: 0.42449620366096497\n",
      "Epoch: 1000, Losses: BARE: 0.8222240581578671, PE: 0.631187766812948\n",
      "Epoch: 1500, Losses: BARE: 0.6933699416418865, PE: 0.4413740007442883\n",
      "New BARE best: 0.4201332926750183, PE best: 0.40366673469543457\n",
      "New PE best: 0.3194689452648163, BARE best: 0.4201332926750183\n",
      "Epoch: 2000, Losses: BARE: 0.6271718150203429, PE: 0.2983846343256504\n",
      "Epoch: 2500, Losses: BARE: 0.5891642876917293, PE: 0.18321656939786524\n",
      "New PE best: 0.30533459782600403, BARE best: 0.4201332926750183\n",
      "Epoch: 3000, Losses: BARE: 0.5651078139661503, PE: 0.08532519319075964\n",
      "Epoch: 3500, Losses: BARE: 0.5480211852488833, PE: -0.012703023162807869\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m traj_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandperm(num_demos)[:batch_size \u001b[38;5;241m*\u001b[39m epoch_iter]\u001b[38;5;241m.\u001b[39mchunk(epoch_iter)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch_iter):\n\u001b[0;32m---> 40\u001b[0m     \u001b[43mprepare_masked_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraj_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     opt0\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     43\u001b[0m     pred0 \u001b[38;5;241m=\u001b[39m m0(obs0, tar_x0, obs_mask)\n",
      "Cell \u001b[0;32mIn[5], line 42\u001b[0m, in \u001b[0;36mprepare_masked_batch\u001b[0;34m(t, traj_ids)\u001b[0m\n\u001b[1;32m     39\u001b[0m obs_mask[i, :n] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     41\u001b[0m tar_x0[i, :m, :dx] \u001b[38;5;241m=\u001b[39m x_train[traj_id, m_ids]\n\u001b[0;32m---> 42\u001b[0m \u001b[43mtar_x0\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m g_train[traj_id]\n\u001b[1;32m     43\u001b[0m tar_x1[i, :m, :dpe] \u001b[38;5;241m=\u001b[39m pe[m_ids]\n\u001b[1;32m     44\u001b[0m tar_x1[i, :m, dpe:] \u001b[38;5;241m=\u001b[39m g_train[traj_id]        \n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "timestamp = int(time.time())\n",
    "root_folder = f'../outputs/comparison/mind_change/freq/bare_pe/{str(timestamp)}/'\n",
    "\n",
    "if not os.path.exists(root_folder):\n",
    "    os.makedirs(root_folder)\n",
    "\n",
    "if not os.path.exists(f'{root_folder}saved_models/'):\n",
    "    os.makedirs(f'{root_folder}saved_models/')\n",
    "\n",
    "img_folder = f'{root_folder}img/'\n",
    "if not os.path.exists(img_folder):\n",
    "    os.makedirs(img_folder)\n",
    "\n",
    "torch.save(y_train, f'{root_folder}y.pt')\n",
    "\n",
    "\n",
    "epochs = 500_000\n",
    "epoch_iter = num_demos // batch_size\n",
    "test_epoch_iter = num_test//batch_size\n",
    "avg_loss0, avg_loss1 = 0, 0\n",
    "loss_report_interval = 500\n",
    "test_per_epoch = 1000\n",
    "min_test_loss0, min_test_loss1 = 1000000, 1000000\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "plot_test = True\n",
    "\n",
    "l0, l1, l2, l3 = [], [], [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss0, epoch_loss1 = 0, 0\n",
    "\n",
    "    traj_ids = torch.randperm(num_demos)[:batch_size * epoch_iter].chunk(epoch_iter)\n",
    "\n",
    "    for i in range(epoch_iter):\n",
    "        prepare_masked_batch(y_train, traj_ids[i])\n",
    "\n",
    "        opt0.zero_grad()\n",
    "        pred0 = m0(obs0, tar_x0, obs_mask)\n",
    "        loss0 = m0.loss(pred0, tar_y, tar_mask)\n",
    "        loss0.backward()\n",
    "        opt0.step()\n",
    "\n",
    "        epoch_loss0 += loss0.item()\n",
    "\n",
    "\n",
    "        opt1.zero_grad()\n",
    "        pred1 = m1(obs1, tar_x1, obs_mask)\n",
    "        loss1 = m1.loss(pred1, tar_y, tar_mask)\n",
    "        loss1.backward()\n",
    "        opt1.step()\n",
    "\n",
    "        epoch_loss1 += loss1.item()\n",
    "\n",
    "\n",
    "    if epoch % test_per_epoch == 0:# and epoch > 0:\n",
    "        test_traj_ids = torch.randperm(num_test)[:batch_size*test_epoch_iter].chunk(test_epoch_iter)\n",
    "        test_loss0, test_loss1 = 0, 0\n",
    "\n",
    "        for j in range(test_epoch_iter):\n",
    "            prepare_masked_test_batch(y_test, test_traj_ids[j])\n",
    "\n",
    "            pred0 = m0.val(test_obs0, test_tar_x0, test_obs_mask)\n",
    "            pred1 = m1.val(test_obs1, test_tar_x1, test_obs_mask)\n",
    "            \n",
    "            if plot_test:\n",
    "                for k in range(batch_size):\n",
    "                    current_n = test_obs_mask[k].sum().item()\n",
    "                    plt.scatter(last_obs_vals[k, :current_n, :dx].cpu().numpy(), test_obs0[k, :current_n, dx+dg:].cpu().numpy(), label='Condition')\n",
    "                    plt.plot(test_tar_y[k, :, 0].cpu().numpy(), label=f\"Groundtruth\")\n",
    "                    plt.plot(pred0[k, :, 0].cpu().numpy(), label=f\"Prediction\")\n",
    "                    \n",
    "                    plt.legend(loc='upper left')\n",
    "                    plt.title(f'Epoch: {epoch}', fontsize=20)\n",
    "                    plt.savefig(f'{img_folder}{epoch}_{test_traj_ids[j][k]}_bare.png')\n",
    "                    plt.clf()\n",
    "\n",
    "                    plt.scatter(last_obs_vals[k, :current_n, :dx].cpu().numpy(), test_obs1[k, :current_n, dpe+dg:].cpu().numpy(), label='Condition')\n",
    "                    plt.plot(test_tar_y[k, :, 0].cpu().numpy(), label=f\"Groundtruth\")\n",
    "                    plt.plot(pred1[k, :, 0].cpu().numpy(), label=f\"Prediction\")\n",
    "                    \n",
    "                    plt.legend(loc='upper left')\n",
    "                    plt.title(f'Epoch: {epoch}', fontsize=20)\n",
    "                    plt.savefig(f'{img_folder}{epoch}_{test_traj_ids[j][k]}_pe.png')\n",
    "                    plt.clf()\n",
    "                    \n",
    "\n",
    "            test_loss0 += mse_loss(pred0[:, :, :m0.output_dim], test_tar_y).item()\n",
    "            test_loss1 += mse_loss(pred1[:, :, :m1.output_dim], test_tar_y).item()\n",
    "        \n",
    "        test_loss0 /= test_epoch_iter\n",
    "        test_loss1 /= test_epoch_iter\n",
    "            \n",
    "        if test_loss0 < min_test_loss0:\n",
    "            min_test_loss0 = test_loss0\n",
    "            print(f'New BARE best: {min_test_loss0}, PE best: {min_test_loss1}')\n",
    "            torch.save(m0_.state_dict(), f'{root_folder}saved_models/bare.pt')\n",
    "\n",
    "        if test_loss1 < min_test_loss1:\n",
    "            min_test_loss1 = test_loss1\n",
    "            print(f'New PE best: {min_test_loss1}, BARE best: {min_test_loss0}')\n",
    "            torch.save(m1_.state_dict(), f'{root_folder}saved_models/pe.pt')\n",
    "\n",
    "\n",
    "    epoch_loss0 /= epoch_iter\n",
    "    epoch_loss1 /= epoch_iter\n",
    "\n",
    "    avg_loss0 += epoch_loss0\n",
    "    avg_loss1 += epoch_loss1\n",
    "\n",
    "    l0.append(epoch_loss0)\n",
    "    l1.append(epoch_loss1)\n",
    "\n",
    "    if epoch % loss_report_interval == 0:\n",
    "        print(\"Epoch: {}, Losses: BARE: {}, PE: {}\".format(epoch, avg_loss0/loss_report_interval, avg_loss1/loss_report_interval))\n",
    "        avg_loss0, avg_loss1 = 0, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last_obs_vals.shape\n",
    "test_obs0[k, current_n, dx:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(l0, f'{root_folder}losses_bare.pt')\n",
    "torch.save(l1, f'{root_folder}losses_pe.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
