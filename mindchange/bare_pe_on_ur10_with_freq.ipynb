{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "folder_path = '../models/'\n",
    "if folder_path not in sys.path:\n",
    "    sys.path.append(folder_path)\n",
    "\n",
    "folder_path = '../data/'\n",
    "if folder_path not in sys.path:\n",
    "    sys.path.append(folder_path)\n",
    "\n",
    "from cnmp import CNMP\n",
    "from positional_encoders import *\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "def get_free_gpu():\n",
    "    gpu_util = []\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        torch.cuda.set_device(i)  # Switch GPU\n",
    "#        gpu_util.append((i, torch.cuda.memory_stats()['reserved_bytes.all.current'] / (1024 ** 2)))\n",
    "        gpu_util.append((i, torch.cuda.utilization()))\n",
    "    gpu_util.sort(key=lambda x: x[1])\n",
    "    return gpu_util[0][0]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    available_gpu = get_free_gpu()\n",
    "    if available_gpu == 0:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda:{available_gpu}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(\"Device :\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([18, 2500, 1]), y_train shape: torch.Size([18, 2500, 7]), g_train shape: torch.Size([18])\n",
      "x_test shape: torch.Size([6, 2500, 1]), y_test shape: torch.Size([6, 2500, 7]), g_test shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "dx, dy, dg, dph, dpe = 1, 7, 1, 0, 27\n",
    "num_demos, num_test = 18, 6\n",
    "num_trajs = num_demos + num_test\n",
    "t_steps = 2500\n",
    "n_max, m_max = 200, 200\n",
    "\n",
    "trajectories, freqs = torch.from_numpy(np.load('../data/ur10/processed/turning_2500.npy')), torch.from_numpy(np.load('../data/ur10/processed/freqs.npy'))\n",
    "max_freq = max(freqs)\n",
    "\n",
    "perm_ids = torch.randperm(num_trajs)\n",
    "train_ids, test_ids = perm_ids[:num_demos], perm_ids[num_demos:]\n",
    "\n",
    "all_x = torch.linspace(0, 1, t_steps).unsqueeze(-1).unsqueeze(0).repeat(num_trajs,1,1)\n",
    "\n",
    "x_train, x_test = all_x[train_ids], all_x[test_ids]\n",
    "y_train, y_test = trajectories[train_ids], trajectories[test_ids]\n",
    "g_train, g_test = freqs[train_ids]/max_freq, freqs[test_ids]/max_freq\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}, g_train shape: {g_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}, g_test shape: {g_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = generate_positional_encoding(t_steps, dpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Colorblind-friendly colors (use perceptually distinct colors)\n",
    "colors = [\n",
    "    '#377eb8',  # Blue\n",
    "    '#ff7f00',  # Orange\n",
    "    '#4daf4a',  # Green\n",
    "    '#f781bf',  # Pink\n",
    "    '#a65628',  # Brown\n",
    "    '#984ea3',  # Purple\n",
    "    '#999999',  # Gray\n",
    "    '#e41a1c',  # Red\n",
    "    '#dede00'   # Yellow\n",
    "]\n",
    "dark_gray = '#4d4d4d'\n",
    "linestyles = [(0, (3, 1, 1, 1, 1, 1)), (0, (1, 1)), '--', (0, (5, 10)), ':', '-.', '-', (0, (1, 3))]\n",
    "plt_size_coeff = 4\n",
    "\n",
    "\n",
    "handles = [Line2D([0], [0], color=dark_gray, lw=2, label='Demonstration'),\n",
    "           Line2D([0], [0], color=colors[0], lw=2, label='CNMP Prediction'), \n",
    "           Line2D([0], [0], color=colors[1], lw=2, label='PEMP Prediction')]  # common in all plots\n",
    "\n",
    "min_y, max_y = -np.pi/2, np.pi/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bare:  269838\n",
      "PE:  283150\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "\n",
    "enc_dims = [256,256,256]\n",
    "dec_dims = [256,256,256]\n",
    "\n",
    "m0_ = CNMP(input_dim=dx+dg, output_dim=dy, n_max=n_max, m_max=m_max, encoder_hidden_dims=enc_dims, decoder_hidden_dims=dec_dims, batch_size=batch_size, device=device)\n",
    "opt0 = torch.optim.Adam(lr=3e-4, params=m0_.parameters())\n",
    "\n",
    "m1_ = CNMP(input_dim=dpe+dg, output_dim=dy, n_max=n_max, m_max=m_max, encoder_hidden_dims=enc_dims, decoder_hidden_dims=dec_dims, batch_size=batch_size, device=device)\n",
    "opt1 = torch.optim.Adam(lr=3e-4, params=m1_.parameters())\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in m0_.parameters())\n",
    "print('Bare: ', pytorch_total_params)\n",
    "pytorch_total_params = sum(p.numel() for p in m1_.parameters())\n",
    "print('PE: ', pytorch_total_params)\n",
    "\n",
    "if torch.__version__ >= \"2.0\":\n",
    "    m0, m1 = torch.compile(m0_), torch.compile(m1_)\n",
    "else:\n",
    "    m0, m1 = m0_, m1_\n",
    "\n",
    "\n",
    "# save network architectures in a txt file:\n",
    "with open('networks.txt', 'w') as f:\n",
    "    f.write(str(enc_dims) + '\\n' + str(dec_dims) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs0 = torch.zeros((batch_size, n_max, dx+dg+dy), dtype=torch.float32, device=device)\n",
    "tar_x0 = torch.zeros((batch_size, m_max, dx+dg), dtype=torch.float32, device=device)\n",
    "\n",
    "obs1 = torch.zeros((batch_size, n_max, dpe+dg+dy), dtype=torch.float32, device=device)\n",
    "tar_x1 = torch.zeros((batch_size, m_max, dpe+dg), dtype=torch.float32, device=device)\n",
    "\n",
    "tar_y = torch.zeros((batch_size, m_max, dy), dtype=torch.float32, device=device)\n",
    "obs_mask = torch.zeros((batch_size, n_max), dtype=torch.bool, device=device)\n",
    "tar_mask = torch.zeros((batch_size, m_max), dtype=torch.bool, device=device)\n",
    "\n",
    "def prepare_masked_batch(t: list, traj_ids: list):\n",
    "    global obs0, tar_x0, obs1, tar_x1, tar_y, obs_mask, tar_mask\n",
    "    obs0.fill_(0)\n",
    "    tar_x0.fill_(0)\n",
    "    obs1.fill_(0)\n",
    "    tar_x1.fill_(0)\n",
    "    tar_y.fill_(0)\n",
    "    obs_mask.fill_(False)\n",
    "    tar_mask.fill_(False)\n",
    "\n",
    "    for i, traj_id in enumerate(traj_ids):\n",
    "        traj = t[traj_id]\n",
    "\n",
    "        n = torch.randint(1, n_max+1, (1,)).item()\n",
    "        m = torch.randint(1, m_max+1, (1,)).item()\n",
    "\n",
    "        permuted_ids = torch.randperm(t_steps)\n",
    "        n_ids = permuted_ids[:n]\n",
    "        m_ids = permuted_ids[n:n+m]\n",
    "\n",
    "        obs0[i, :n, :dx] = x_train[traj_id, n_ids]  # t\n",
    "        obs0[i, :n, dx:dx+dg] = g_train[traj_id]  # gamma\n",
    "        obs0[i, :n, dx+dg:] = traj[n_ids]  # SM(t)\n",
    "\n",
    "        obs1[i, :n, :dpe] = pe[n_ids]  # PE(t)\n",
    "        obs1[i, :n, dpe:dpe+dg] = g_train[traj_id]  # gamma\n",
    "        obs1[i, :n, dpe+dg:] = traj[n_ids]  # SM(t)\n",
    "\n",
    "        obs_mask[i, :n] = True\n",
    "        \n",
    "        tar_x0[i, :m, :dx] = x_train[traj_id, m_ids]\n",
    "        tar_x0[i, :m, dx:] = g_train[traj_id]\n",
    "        tar_x1[i, :m, :dpe] = pe[m_ids]\n",
    "        tar_x1[i, :m, dpe:] = g_train[traj_id]        \n",
    "        \n",
    "        tar_y[i, :m] = traj[m_ids]\n",
    "        tar_mask[i, :m] = True\n",
    "\n",
    "\n",
    "test_obs0 = torch.zeros((batch_size, n_max, dx+dg+dy), dtype=torch.float32, device=device)\n",
    "test_tar_x0 = torch.zeros((batch_size, t_steps, dx+dg), dtype=torch.float32, device=device)\n",
    "\n",
    "test_obs1 = torch.zeros((batch_size, n_max, dpe+dg+dy), dtype=torch.float32, device=device)\n",
    "test_tar_x1 = torch.zeros((batch_size, t_steps, dpe+dg), dtype=torch.float32, device=device)\n",
    "\n",
    "test_tar_y = torch.zeros((batch_size, t_steps, dy), dtype=torch.float32, device=device)\n",
    "test_obs_mask = torch.zeros((batch_size, n_max), dtype=torch.bool, device=device)\n",
    "\n",
    "def prepare_masked_test_batch(t: list, traj_ids: list, fixed_ind=None):\n",
    "    global test_obs0, test_tar_x0, test_obs1, test_tar_x1, test_tar_y, test_obs_mask\n",
    "    test_obs0.fill_(0)\n",
    "    test_tar_x0.fill_(0)\n",
    "    test_obs1.fill_(0)\n",
    "    test_tar_x1.fill_(0)\n",
    "    test_tar_y.fill_(0)\n",
    "    test_obs_mask.fill_(False)\n",
    "\n",
    "    for i, traj_id in enumerate(traj_ids):\n",
    "        traj = t[traj_id]\n",
    "\n",
    "        # n = num_peaks #torch.randint(5, n_max, (1,)).item()\n",
    "        n = torch.randint(1, n_max+1, (1,)).item()\n",
    "\n",
    "        permuted_ids = torch.randperm(t_steps)\n",
    "        n_ids = permuted_ids[:n]\n",
    "        m_ids = torch.arange(t_steps)\n",
    "\n",
    "        if fixed_ind != None:\n",
    "            for p in range(n):\n",
    "                n_ids[p] = fixed_ind[i, p]\n",
    "            # n_ids[-1] = fixed_ind[i]\n",
    "\n",
    "        test_obs0[i, :n, :dx] = x_test[traj_id, n_ids]  # t\n",
    "        test_obs0[i, :n, dx:dx+dg] = g_test[traj_id]\n",
    "        test_obs0[i, :n, dx+dg:] = traj[n_ids]  # SM(t)\n",
    "\n",
    "        test_obs1[i, :n, :dpe] = pe[n_ids]  # PE(t)\n",
    "        test_obs1[i, :n, dpe:dpe+dg] = g_test[traj_id]\n",
    "        test_obs1[i, :n, dpe+dg:] = traj[n_ids]\n",
    "\n",
    "        test_obs_mask[i, :n] = True\n",
    "        \n",
    "        test_tar_x0[i, :, :dx] = x_test[traj_id, m_ids]\n",
    "        test_tar_x1[i, :, :dpe] = pe[m_ids]\n",
    "\n",
    "        test_tar_y[i] = traj[m_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New BARE best: 0.14494923253854117, PE best: 1000000\n",
      "New PE best: 0.137632022301356, BARE best: 0.14494923253854117\n",
      "Epoch: 0, Losses: BARE: 0.007825711250305175, PE: 0.00747809558444553\n",
      "Epoch: 1000, Losses: BARE: -9.641847108902205, PE: -25.5148370604879\n",
      "Epoch: 2000, Losses: BARE: -12.823681219816208, PE: -38.023873904771285\n",
      "Epoch: 3000, Losses: BARE: -16.80475167147319, PE: -41.75093436682231\n",
      "Epoch: 4000, Losses: BARE: -17.37336259275014, PE: -48.80723710560795\n",
      "New BARE best: 0.006285740062594414, PE best: 0.137632022301356\n",
      "New PE best: 0.002333169764218231, BARE best: 0.006285740062594414\n",
      "Epoch: 5000, Losses: BARE: -22.904994451297654, PE: -47.32977036766209\n",
      "Epoch: 6000, Losses: BARE: -26.257028032508146, PE: -46.94230960955878\n",
      "Epoch: 7000, Losses: BARE: -29.16001889781819, PE: -49.7127359274891\n",
      "Epoch: 8000, Losses: BARE: -31.046923625561984, PE: -48.9187422194878\n",
      "Epoch: 9000, Losses: BARE: -32.26629843918482, PE: -49.11329290623142\n",
      "Epoch: 10000, Losses: BARE: -32.87169935459559, PE: -46.14084400569067\n",
      "Epoch: 11000, Losses: BARE: -33.73393855773742, PE: -50.821552669021735\n",
      "Epoch: 12000, Losses: BARE: -36.43364576845701, PE: -50.55927034374083\n",
      "Epoch: 13000, Losses: BARE: -39.05736598523453, PE: -45.81204817741116\n",
      "Epoch: 14000, Losses: BARE: -40.85595053017148, PE: -52.786805772145556\n",
      "New PE best: 0.0013503726028526823, BARE best: 0.006285740062594414\n",
      "Epoch: 15000, Losses: BARE: -41.830423442019345, PE: -53.453327555762314\n",
      "Epoch: 16000, Losses: BARE: -42.43699996558824, PE: -49.75488022265167\n",
      "Epoch: 17000, Losses: BARE: -42.95515402731636, PE: -59.39891920900349\n",
      "Epoch: 18000, Losses: BARE: -43.29238215157727, PE: -58.70595425997834\n",
      "Epoch: 19000, Losses: BARE: -43.723184313217835, PE: -52.5107857980463\n",
      "Epoch: 20000, Losses: BARE: -44.26527145564555, PE: -48.723905761188874\n",
      "Epoch: 21000, Losses: BARE: -44.78050484445364, PE: -54.51601393826144\n",
      "Epoch: 22000, Losses: BARE: -45.713228589110855, PE: -56.16258599894572\n",
      "Epoch: 23000, Losses: BARE: -46.256027348597904, PE: -61.90003143469497\n",
      "Epoch: 24000, Losses: BARE: -46.98573503822132, PE: -62.321624747170326\n",
      "New PE best: 0.0006531726685352623, BARE best: 0.006285740062594414\n",
      "Epoch: 25000, Losses: BARE: -47.797456719610466, PE: -61.074078626010134\n",
      "Epoch: 26000, Losses: BARE: -47.78514027789316, PE: -61.30666107775769\n",
      "Epoch: 27000, Losses: BARE: -47.286496338109224, PE: -61.560912208265684\n",
      "Epoch: 28000, Losses: BARE: -48.34226285195355, PE: -61.00257832193374\n",
      "Epoch: 29000, Losses: BARE: -49.02834955565132, PE: -63.02682493474748\n",
      "Epoch: 30000, Losses: BARE: -49.20764793486071, PE: -68.84310894033649\n",
      "Epoch: 31000, Losses: BARE: -49.89348230155307, PE: -67.09799069775484\n",
      "Epoch: 32000, Losses: BARE: -50.67945332066222, PE: -66.3028176220257\n",
      "Epoch: 33000, Losses: BARE: -51.513970994207625, PE: -69.74502844407826\n",
      "Epoch: 34000, Losses: BARE: -52.369696790165406, PE: -69.24474521976047\n",
      "Epoch: 35000, Losses: BARE: -52.54155727316276, PE: -70.66444809468582\n",
      "Epoch: 36000, Losses: BARE: -52.64708473422792, PE: -70.26440569867032\n",
      "Epoch: 37000, Losses: BARE: -53.2560892190933, PE: -71.84601817258205\n",
      "Epoch: 38000, Losses: BARE: -53.417426389111405, PE: -71.80925057686703\n",
      "Epoch: 39000, Losses: BARE: -53.63077571119203, PE: -71.80461289575372\n",
      "Epoch: 40000, Losses: BARE: -54.13429416253827, PE: -64.9503636849589\n",
      "Epoch: 41000, Losses: BARE: -53.98523519592811, PE: -71.66566922314959\n",
      "Epoch: 42000, Losses: BARE: -54.34626517821674, PE: -72.12841287040719\n",
      "Epoch: 43000, Losses: BARE: -54.604548328505565, PE: -72.18297771559826\n",
      "Epoch: 44000, Losses: BARE: -54.89306111470862, PE: -72.46141303210787\n",
      "Epoch: 45000, Losses: BARE: -55.23183459658098, PE: -72.8352155509525\n",
      "Epoch: 46000, Losses: BARE: -54.814971350828785, PE: -72.4366950694191\n",
      "Epoch: 47000, Losses: BARE: -55.23643505851431, PE: -72.94938917382548\n",
      "Epoch: 48000, Losses: BARE: -55.240580191665195, PE: -73.09457505692376\n",
      "Epoch: 49000, Losses: BARE: -55.596228214740755, PE: -73.00379898325609\n",
      "Epoch: 50000, Losses: BARE: -55.40465831838712, PE: -67.48602214686079\n",
      "Epoch: 51000, Losses: BARE: -55.787592864672376, PE: -68.91813381630183\n",
      "Epoch: 52000, Losses: BARE: -55.93984140449094, PE: -72.05162735154889\n",
      "Epoch: 53000, Losses: BARE: -56.440920867337205, PE: -73.02573663923468\n",
      "Epoch: 54000, Losses: BARE: -56.165620745658906, PE: -73.3555826191373\n",
      "Epoch: 55000, Losses: BARE: -56.326104619503084, PE: -72.23195589192706\n",
      "Epoch: 56000, Losses: BARE: -56.62481956815724, PE: -73.15109507200451\n",
      "Epoch: 57000, Losses: BARE: -56.55205594356839, PE: -65.02023862875828\n",
      "Epoch: 58000, Losses: BARE: -56.06301539701888, PE: -71.09585877397325\n",
      "Epoch: 59000, Losses: BARE: -56.40133387041089, PE: -72.87241376792062\n",
      "Epoch: 60000, Losses: BARE: -56.739764466285735, PE: -73.48355667241414\n",
      "Epoch: 61000, Losses: BARE: -56.93333580123045, PE: -43.31838109411132\n",
      "Epoch: 62000, Losses: BARE: -57.048977752155785, PE: -69.96740418974555\n",
      "Epoch: 63000, Losses: BARE: -57.021331094132584, PE: -71.88916730308526\n",
      "Epoch: 64000, Losses: BARE: -57.46990013249718, PE: -71.77098400465641\n",
      "Epoch: 65000, Losses: BARE: -57.64488960112465, PE: -73.15827458869077\n",
      "Epoch: 66000, Losses: BARE: -58.04096878782906, PE: -73.25461941528312\n",
      "Epoch: 67000, Losses: BARE: -57.995261506133716, PE: -72.73555044407323\n",
      "Epoch: 68000, Losses: BARE: -58.05133192565045, PE: -73.15313064002997\n",
      "Epoch: 69000, Losses: BARE: -58.4982165150245, PE: -73.58205056042148\n",
      "Epoch: 70000, Losses: BARE: -59.125604099273694, PE: -73.50038232739766\n",
      "Epoch: 71000, Losses: BARE: -59.28678100310429, PE: -73.9841967548795\n",
      "Epoch: 72000, Losses: BARE: -59.28875471390612, PE: -73.87025835948533\n",
      "Epoch: 73000, Losses: BARE: -59.68792404331109, PE: -73.26356383599176\n",
      "Epoch: 74000, Losses: BARE: -60.38769338491222, PE: -74.07925930319887\n",
      "Epoch: 75000, Losses: BARE: -59.99839542632636, PE: -74.22159779760581\n",
      "Epoch: 76000, Losses: BARE: -60.422830448362596, PE: -73.61219715457487\n",
      "Epoch: 77000, Losses: BARE: -60.48351783498126, PE: -73.77815672217463\n",
      "Epoch: 78000, Losses: BARE: -60.42005621496833, PE: -74.12739927440218\n",
      "Epoch: 79000, Losses: BARE: -60.73072902848978, PE: -74.32677117602032\n",
      "Epoch: 80000, Losses: BARE: -60.610007921430785, PE: -74.1187820428476\n",
      "Epoch: 81000, Losses: BARE: -60.67365332264368, PE: -74.32893517027976\n",
      "Epoch: 82000, Losses: BARE: -60.68663365766735, PE: -74.53191117837706\n",
      "Epoch: 83000, Losses: BARE: -61.00448222033182, PE: -74.64559910604699\n",
      "Epoch: 84000, Losses: BARE: -61.03639661608809, PE: -74.78838592274977\n",
      "Epoch: 85000, Losses: BARE: -61.08092266909287, PE: -74.80149899885384\n",
      "Epoch: 86000, Losses: BARE: -61.0984036323626, PE: -74.65618635288877\n",
      "Epoch: 87000, Losses: BARE: -61.51583738146894, PE: -74.83995752843218\n",
      "Epoch: 88000, Losses: BARE: -61.69277691173549, PE: -74.70187344635858\n",
      "Epoch: 89000, Losses: BARE: -61.74023949363493, PE: -74.55117083740234\n",
      "Epoch: 90000, Losses: BARE: -62.005116852230415, PE: -74.60257861322826\n",
      "Epoch: 91000, Losses: BARE: -62.2937106229994, PE: -74.43256726365625\n",
      "Epoch: 92000, Losses: BARE: -61.94624591374397, PE: -74.83581983502727\n",
      "Epoch: 93000, Losses: BARE: -62.52720683036901, PE: -75.02743194601261\n",
      "Epoch: 94000, Losses: BARE: -62.62211082379023, PE: -74.72700141143801\n",
      "Epoch: 95000, Losses: BARE: -62.542078284528436, PE: -74.75271802457172\n",
      "Epoch: 96000, Losses: BARE: -62.083303581184865, PE: -75.01687047153044\n",
      "Epoch: 97000, Losses: BARE: -62.64883853329557, PE: -75.03382301923965\n",
      "Epoch: 98000, Losses: BARE: -62.787044250594214, PE: -74.99621978251137\n",
      "Epoch: 99000, Losses: BARE: -62.6529355368614, PE: -74.8909869965447\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "timestamp = int(time.time())\n",
    "root_folder = f'../outputs/ur10/bare_pe/{str(timestamp)}/'\n",
    "\n",
    "if not os.path.exists(root_folder):\n",
    "    os.makedirs(root_folder)\n",
    "\n",
    "if not os.path.exists(f'{root_folder}saved_models/'):\n",
    "    os.makedirs(f'{root_folder}saved_models/')\n",
    "\n",
    "img_folder = f'{root_folder}img/'\n",
    "if not os.path.exists(img_folder):\n",
    "    os.makedirs(img_folder)\n",
    "\n",
    "torch.save(x_train, f'{root_folder}x.pt')\n",
    "torch.save(y_train, f'{root_folder}y.pt')\n",
    "torch.save(g_train, f'{root_folder}g.pt')\n",
    "torch.save(x_test, f'{root_folder}x_test.pt')\n",
    "torch.save(y_test, f'{root_folder}y_test.pt')\n",
    "torch.save(g_test, f'{root_folder}g_test.pt')\n",
    "\n",
    "\n",
    "epochs = 100_000\n",
    "epoch_iter = num_demos // batch_size\n",
    "test_epoch_iter = num_test//batch_size\n",
    "avg_loss0, avg_loss1 = 0, 0\n",
    "loss_report_interval = 1000\n",
    "test_per_epoch = 5000\n",
    "min_test_loss0, min_test_loss1 = 1000000, 1000000\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "plot_test = True\n",
    "\n",
    "l0, l1 = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss0, epoch_loss1 = 0, 0\n",
    "\n",
    "    traj_ids = torch.randperm(num_demos)[:batch_size * epoch_iter].chunk(epoch_iter)\n",
    "\n",
    "    for i in range(epoch_iter):\n",
    "        prepare_masked_batch(y_train, traj_ids[i])\n",
    "\n",
    "        opt0.zero_grad()\n",
    "        pred0 = m0(obs0, tar_x0, obs_mask)\n",
    "        loss0 = m0.loss(pred0, tar_y, tar_mask)\n",
    "        loss0.backward()\n",
    "        opt0.step()\n",
    "\n",
    "        epoch_loss0 += loss0.item()\n",
    "\n",
    "\n",
    "        opt1.zero_grad()\n",
    "        pred1 = m1(obs1, tar_x1, obs_mask)\n",
    "        loss1 = m1.loss(pred1, tar_y, tar_mask)\n",
    "        loss1.backward()\n",
    "        opt1.step()\n",
    "\n",
    "        epoch_loss1 += loss1.item()\n",
    "\n",
    "\n",
    "    if epoch % test_per_epoch == 0:# and epoch > 0:\n",
    "        test_traj_ids = torch.randperm(num_test)[:batch_size*test_epoch_iter].chunk(test_epoch_iter)\n",
    "        test_loss0, test_loss1 = 0, 0\n",
    "\n",
    "        for j in range(test_epoch_iter):\n",
    "            prepare_masked_test_batch(y_test, test_traj_ids[j])\n",
    "\n",
    "            pred0 = m0.val(test_obs0, test_tar_x0, test_obs_mask)  # (batch_size, t_steps, 2*dy)\n",
    "            pred1 = m1.val(test_obs1, test_tar_x1, test_obs_mask)  # (batch_size, t_steps, 2*dy)\n",
    "            \n",
    "            if plot_test:\n",
    "                epoch_code = str(epoch).zfill(len(str(epochs))-1)\n",
    "                for k in range(batch_size):\n",
    "                    current_n = test_obs_mask[k].sum().item()  # n points inside the condition\n",
    "                    plt_x_data = x_test[test_traj_ids[j][0], :]  # common for all plots\n",
    "                    fig, ax = plt.subplots(2, dy, figsize=(dy*plt_size_coeff, 2*plt_size_coeff))\n",
    "                    for dimension in range(dy):\n",
    "                        pred_cnmp = pred0[k, :, dimension].cpu().numpy()\n",
    "                        pred_pemp = pred1[k, :, dimension].cpu().numpy()\n",
    "                        # max_y = max(np.max(pred_cnmp), np.max(pred_pemp))\n",
    "                        # min_y = min(np.min(pred_cnmp), np.min(pred_pemp))\n",
    "\n",
    "                        ax[0, dimension].set_ylim(min_y, max_y)\n",
    "\n",
    "                        ax[0, dimension].scatter(test_obs0[k, :current_n, :dx].cpu().numpy(), test_obs0[k, :current_n, dx+dg+dimension].cpu().numpy(), color='black', s=30)\n",
    "                        ax[0, dimension].plot(plt_x_data, test_tar_y[k, :, dimension].cpu().numpy(), color=dark_gray)\n",
    "                        ax[0, dimension].plot(plt_x_data, pred_cnmp, color=colors[0])  # bare prediction\n",
    "                        ax[0, dimension].grid(color='gray', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "                        ax[1, dimension].set_ylim(min_y, max_y)\n",
    "\n",
    "                        ax[1, dimension].scatter(test_obs0[k, :current_n, :dx].cpu().numpy(), test_obs0[k, :current_n, dx+dg+dimension].cpu().numpy(), color='black', s=30)\n",
    "                        ax[1, dimension].plot(plt_x_data, test_tar_y[k, :, dimension].cpu().numpy(), color=dark_gray)\n",
    "                        ax[1, dimension].plot(plt_x_data, pred_pemp, color=colors[1])  # pemp prediction\n",
    "                        ax[1, dimension].grid(color='gray', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "                    fig.suptitle(f'Epoch: {epoch}', fontsize=24)\n",
    "                    fig.legend(handles=handles, loc='upper right', fontsize=24, frameon=True, framealpha=1, prop=dict(weight='bold'), handlelength=3, handleheight=2)\n",
    "                    plt.savefig(f'{img_folder}{epoch_code}_{test_traj_ids[j][k]}.png')\n",
    "                    plt.close()                    \n",
    "\n",
    "            test_loss0 += mse_loss(pred0[:, :, :m0.output_dim], test_tar_y).item()\n",
    "            test_loss1 += mse_loss(pred1[:, :, :m1.output_dim], test_tar_y).item()\n",
    "        \n",
    "        test_loss0 /= test_epoch_iter\n",
    "        test_loss1 /= test_epoch_iter\n",
    "            \n",
    "        if test_loss0 < min_test_loss0:\n",
    "            min_test_loss0 = test_loss0\n",
    "            print(f'New BARE best: {min_test_loss0}, PE best: {min_test_loss1}')\n",
    "            torch.save(m0_.state_dict(), f'{root_folder}saved_models/bare.pt')\n",
    "\n",
    "        if test_loss1 < min_test_loss1:\n",
    "            min_test_loss1 = test_loss1\n",
    "            print(f'New PE best: {min_test_loss1}, BARE best: {min_test_loss0}')\n",
    "            torch.save(m1_.state_dict(), f'{root_folder}saved_models/pe.pt')\n",
    "\n",
    "\n",
    "    epoch_loss0 /= epoch_iter\n",
    "    epoch_loss1 /= epoch_iter\n",
    "\n",
    "    avg_loss0 += epoch_loss0\n",
    "    avg_loss1 += epoch_loss1\n",
    "\n",
    "    l0.append(epoch_loss0)\n",
    "    l1.append(epoch_loss1)\n",
    "\n",
    "    if epoch % loss_report_interval == 0:\n",
    "        print(\"Epoch: {}, Losses: BARE: {}, PE: {}\".format(epoch, avg_loss0/loss_report_interval, avg_loss1/loss_report_interval))\n",
    "        avg_loss0, avg_loss1 = 0, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(l0, f'{root_folder}losses_bare.pt')\n",
    "torch.save(l1, f'{root_folder}losses_pe.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
