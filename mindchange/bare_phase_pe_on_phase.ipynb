{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "folder_path = '../models/'\n",
    "if folder_path not in sys.path:\n",
    "    sys.path.append(folder_path)\n",
    "\n",
    "folder_path = '../data/'\n",
    "if folder_path not in sys.path:\n",
    "    sys.path.append(folder_path)\n",
    "\n",
    "from cnmp import CNMP\n",
    "\n",
    "from data_generators import *\n",
    "from positional_encoders import *\n",
    "from plotters import *\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "def get_free_gpu():\n",
    "    gpu_util = []\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        torch.cuda.set_device(i)  # Switch GPU\n",
    "#        gpu_util.append((i, torch.cuda.memory_stats()['reserved_bytes.all.current'] / (1024 ** 2)))\n",
    "        gpu_util.append((i, torch.cuda.utilization()))\n",
    "    gpu_util.sort(key=lambda x: x[1])\n",
    "    return gpu_util[0][0]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    available_gpu = get_free_gpu()\n",
    "    if available_gpu == 0:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda:{available_gpu}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(\"Device :\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([360, 1200, 1]), y_train shape: torch.Size([360, 1200, 1])\n",
      "x_test shape: torch.Size([40, 1200, 1]), y_test shape: torch.Size([40, 1200, 1])\n"
     ]
    }
   ],
   "source": [
    "dx, dy, dg, dph, dpe = 1, 1, 0, 1, 27\n",
    "num_demos, num_test = 360, 40\n",
    "num_trajs = num_demos + num_test\n",
    "t_steps = 1200\n",
    "n_max, m_max = 100, 100\n",
    "\n",
    "trajectories, phases = generate_cyclic_trajectories_with_random_cycles(num_trajs=num_trajs)\n",
    "\n",
    "perm_ids = torch.randperm(num_trajs)\n",
    "train_ids, test_ids = perm_ids[:num_demos], perm_ids[num_demos:]\n",
    "\n",
    "all_x = torch.linspace(0, 1, t_steps).unsqueeze(-1).unsqueeze(0).repeat(num_trajs,1,1)\n",
    "\n",
    "x_train, x_test = all_x[train_ids], all_x[test_ids]\n",
    "y_train, y_test = trajectories[train_ids], trajectories[test_ids]\n",
    "p_train, p_test = phases[train_ids], phases[test_ids]\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpe_aug = dpe + dg\n",
    "\n",
    "pe_train = torch.zeros((num_demos, t_steps, dpe))\n",
    "for i in range(num_demos):\n",
    "    pe_train[i] = generate_positional_encoding_for_phase(p_train[i], dpe)\n",
    "\n",
    "pe_test = torch.zeros((num_test, t_steps, dpe))\n",
    "for i in range(num_test):\n",
    "    pe_test[i] = generate_positional_encoding_for_phase(p_test[i], dpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bare:  33794\n",
      "PH:  33794\n",
      "PE:  40450\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "enc_dims = [128,128]\n",
    "dec_dims = [128,128]\n",
    "\n",
    "m0_ = CNMP(input_dim=dx, output_dim=dy, n_max=n_max, m_max=m_max, encoder_hidden_dims=enc_dims, decoder_hidden_dims=dec_dims, batch_size=batch_size, device=device)\n",
    "opt0 = torch.optim.Adam(lr=3e-4, params=m0_.parameters())\n",
    "\n",
    "m1_ = CNMP(input_dim=dx, output_dim=dy, n_max=n_max, m_max=m_max, encoder_hidden_dims=enc_dims, decoder_hidden_dims=dec_dims, batch_size=batch_size, device=device)\n",
    "opt1 = torch.optim.Adam(lr=3e-4, params=m1_.parameters())\n",
    "\n",
    "m2_ = CNMP(input_dim=dpe, output_dim=dy, n_max=n_max, m_max=m_max, encoder_hidden_dims=enc_dims, decoder_hidden_dims=dec_dims, batch_size=batch_size, device=device)\n",
    "opt2 = torch.optim.Adam(lr=3e-4, params=m2_.parameters())\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in m0_.parameters())\n",
    "print('Bare: ', pytorch_total_params)\n",
    "pytorch_total_params = sum(p.numel() for p in m1_.parameters())\n",
    "print('PH: ', pytorch_total_params)\n",
    "pytorch_total_params = sum(p.numel() for p in m2_.parameters())\n",
    "print('PE: ', pytorch_total_params)\n",
    "\n",
    "if torch.__version__ >= \"2.0\":\n",
    "    m0, m1, m2 = torch.compile(m0_), torch.compile(m1_), torch.compile(m2_)\n",
    "else:\n",
    "    m0, m1, m2 = m0_, m1_, m2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs0 = torch.zeros((batch_size, n_max, dx+dg+dy), dtype=torch.float32, device=device)\n",
    "tar_x0 = torch.zeros((batch_size, m_max, dx+dg), dtype=torch.float32, device=device)\n",
    "\n",
    "obs1 = torch.zeros((batch_size, n_max, dph+dy), dtype=torch.float32, device=device)\n",
    "tar_x1 = torch.zeros((batch_size, m_max, dph), dtype=torch.float32, device=device)\n",
    "\n",
    "obs2 = torch.zeros((batch_size, n_max, dpe_aug+dy), dtype=torch.float32, device=device)\n",
    "tar_x2 = torch.zeros((batch_size, m_max, dpe_aug), dtype=torch.float32, device=device)\n",
    "\n",
    "tar_y = torch.zeros((batch_size, m_max, dy), dtype=torch.float32, device=device)\n",
    "obs_mask = torch.zeros((batch_size, n_max), dtype=torch.bool, device=device)\n",
    "tar_mask = torch.zeros((batch_size, m_max), dtype=torch.bool, device=device)\n",
    "\n",
    "def prepare_masked_batch(t: list, traj_ids: list):\n",
    "    global obs0, tar_x0, obs1, tar_x1, obs2, tar_x2, tar_y, obs_mask, tar_mask\n",
    "    obs0.fill_(0)\n",
    "    tar_x0.fill_(0)\n",
    "    obs1.fill_(0)\n",
    "    tar_x1.fill_(0)\n",
    "    obs2.fill_(0)\n",
    "    tar_x2.fill_(0)\n",
    "    tar_y.fill_(0)\n",
    "    obs_mask.fill_(False)\n",
    "    tar_mask.fill_(False)\n",
    "\n",
    "    for i, traj_id in enumerate(traj_ids):\n",
    "        traj = t[traj_id]\n",
    "\n",
    "        n = torch.randint(1, n_max+1, (1,)).item()\n",
    "        m = torch.randint(1, m_max+1, (1,)).item()\n",
    "\n",
    "        permuted_ids = torch.randperm(t_steps)\n",
    "        n_ids = permuted_ids[:n]\n",
    "        m_ids = permuted_ids[n:n+m]\n",
    "\n",
    "        obs0[i, :n, :dx] = x_train[traj_id, n_ids]  # t\n",
    "        obs1[i, :n, :dph] = p_train[traj_id, n_ids]  # phase(t)\n",
    "        obs2[i, :n, :dpe] = pe_train[traj_id, n_ids]  # PE(phase(t))\n",
    "\n",
    "        obs0[i, :n, dx:] = traj[n_ids]  # SM(t)\n",
    "        obs1[i, :n, dx:] = traj[n_ids]  # SM(t)\n",
    "        obs2[i, :n, dx:] = traj[n_ids]  # SM(t)\n",
    "\n",
    "        obs_mask[i, :n] = True\n",
    "        \n",
    "        tar_x0[i, :m, :dx] = x_train[traj_id, m_ids]\n",
    "        tar_x1[i, :m, :dph] = p_train[traj_id, m_ids]\n",
    "        tar_x2[i, :m, :dpe] = pe_train[traj_id, m_ids]\n",
    "\n",
    "        tar_y[i, :m] = traj[m_ids]\n",
    "        tar_mask[i, :m] = True\n",
    "\n",
    "\n",
    "test_obs0 = torch.zeros((batch_size, n_max, dx+dg+dy), dtype=torch.float32, device=device)\n",
    "test_tar_x0 = torch.zeros((batch_size, t_steps, dx+dg), dtype=torch.float32, device=device)\n",
    "\n",
    "test_obs1 = torch.zeros((batch_size, n_max, dpe_aug+dy), dtype=torch.float32, device=device)\n",
    "test_tar_x1 = torch.zeros((batch_size, t_steps, dpe_aug), dtype=torch.float32, device=device)\n",
    "\n",
    "test_obs2 = torch.zeros((batch_size, n_max, dpe_aug+dy), dtype=torch.float32, device=device)\n",
    "test_tar_x2 = torch.zeros((batch_size, t_steps, dpe_aug), dtype=torch.float32, device=device)\n",
    "\n",
    "test_tar_y = torch.zeros((batch_size, t_steps, dy), dtype=torch.float32, device=device)\n",
    "test_obs_mask = torch.zeros((batch_size, n_max), dtype=torch.bool, device=device)\n",
    "last_obs_vals = torch.zeros((batch_size, n_max, dx), dtype=torch.int32, device=device)  # only for plotting\n",
    "\n",
    "def prepare_masked_test_batch(t: list, traj_ids: list, fixed_ind=None):\n",
    "    global test_obs0, test_tar_x0, test_obs1, test_tar_x1, test_obs2, test_tar_x2, test_tar_y, test_obs_mask, last_obs_vals\n",
    "    test_obs0.fill_(0)\n",
    "    test_tar_x0.fill_(0)\n",
    "    test_obs1.fill_(0)\n",
    "    test_tar_x1.fill_(0)\n",
    "    test_obs2.fill_(0)\n",
    "    test_tar_x2.fill_(0)\n",
    "    test_tar_y.fill_(0)\n",
    "    test_obs_mask.fill_(False)\n",
    "    last_obs_vals.fill_(0)\n",
    "\n",
    "    for i, traj_id in enumerate(traj_ids):\n",
    "        traj = t[traj_id]\n",
    "\n",
    "        # n = num_peaks #torch.randint(5, n_max, (1,)).item()\n",
    "        n = torch.randint(1, n_max+1, (1,)).item()\n",
    "\n",
    "        permuted_ids = torch.randperm(t_steps)\n",
    "        n_ids = permuted_ids[:n]\n",
    "        m_ids = torch.arange(t_steps)\n",
    "\n",
    "        if fixed_ind != None:\n",
    "            for p in range(n):\n",
    "                n_ids[p] = fixed_ind[i, p]\n",
    "            # n_ids[-1] = fixed_ind[i]\n",
    "\n",
    "        test_obs0[i, :n, :dx] = x_test[traj_id, n_ids]  # t\n",
    "        test_obs1[i, :n, :dph] = p_test[traj_id, n_ids]  # phase(t)\n",
    "        test_obs2[i, :n, :dpe] = pe_test[traj_id, n_ids]  # PE(phase(t))\n",
    "\n",
    "        last_obs_vals[i, :n] = n_ids.unsqueeze(-1)\n",
    "        test_obs_mask[i, :n] = True\n",
    "        \n",
    "        test_tar_x0[i, :, :dx] = x_test[traj_id, m_ids]\n",
    "        test_tar_x1[i, :, :dph] = p_test[traj_id, m_ids]\n",
    "        test_tar_x2[i, :, :dpe] = pe_test[traj_id, m_ids]\n",
    "\n",
    "        test_tar_y[i] = traj[m_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "timestamp = int(time.time())\n",
    "root_folder = f'../outputs/comparison/mind_change/bare_ph_pe/{str(timestamp)}/'\n",
    "\n",
    "if not os.path.exists(root_folder):\n",
    "    os.makedirs(root_folder)\n",
    "\n",
    "if not os.path.exists(f'{root_folder}saved_models/'):\n",
    "    os.makedirs(f'{root_folder}saved_models/')\n",
    "\n",
    "img_folder = f'{root_folder}img/'\n",
    "if not os.path.exists(img_folder):\n",
    "    os.makedirs(img_folder)\n",
    "\n",
    "torch.save(y_train, f'{root_folder}y.pt')\n",
    "\n",
    "\n",
    "epochs = 500_000\n",
    "epoch_iter = num_demos // batch_size\n",
    "test_epoch_iter = num_test//batch_size\n",
    "avg_loss0, avg_loss1, avg_loss2 = 0, 0, 0\n",
    "loss_report_interval = 500\n",
    "test_per_epoch = 1000\n",
    "min_test_loss0, min_test_loss1, min_test_loss2 = 1000000, 1000000, 1000000\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "plot_test = True\n",
    "\n",
    "l0, l1, l2 = [], [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss0, epoch_loss1, epoch_loss2 = 0, 0, 0\n",
    "\n",
    "    traj_ids = torch.randperm(num_demos)[:batch_size * epoch_iter].chunk(epoch_iter)\n",
    "\n",
    "    for i in range(epoch_iter):\n",
    "        prepare_masked_batch(y_train, traj_ids[i])\n",
    "\n",
    "        opt0.zero_grad()\n",
    "        pred0 = m0(obs0, tar_x0, obs_mask)\n",
    "        loss0 = m0.loss(pred0, tar_y, tar_mask)\n",
    "        loss0.backward()\n",
    "        opt0.step()\n",
    "\n",
    "        epoch_loss0 += loss0.item()\n",
    "\n",
    "\n",
    "        opt1.zero_grad()\n",
    "        pred1 = m1(obs1, tar_x1, obs_mask)\n",
    "        loss1 = m1.loss(pred1, tar_y, tar_mask)\n",
    "        loss1.backward()\n",
    "        opt1.step()\n",
    "\n",
    "        epoch_loss1 += loss1.item()\n",
    "\n",
    "\n",
    "        opt2.zero_grad()\n",
    "        pred2 = m2(obs2, tar_x2, obs_mask)\n",
    "        loss2 = m2.loss(pred2, tar_y, tar_mask)\n",
    "        loss2.backward()\n",
    "        opt2.step()\n",
    "\n",
    "        epoch_loss2 += loss2.item()\n",
    "\n",
    "\n",
    "    if epoch % test_per_epoch == 0:# and epoch > 0:\n",
    "        test_traj_ids = torch.randperm(num_test)[:batch_size*test_epoch_iter].chunk(test_epoch_iter)\n",
    "        test_loss0, test_loss1, test_loss2 = 0, 0, 0\n",
    "\n",
    "        for j in range(test_epoch_iter):\n",
    "            prepare_masked_test_batch(y_test, test_traj_ids[j])\n",
    "\n",
    "            pred0 = m0.val(test_obs0, test_tar_x0, test_obs_mask)\n",
    "            pred1 = m1.val(test_obs1, test_tar_x1, test_obs_mask)\n",
    "            pred2 = m2.val(test_obs2, test_tar_x2, test_obs_mask)\n",
    "            \n",
    "            if plot_test:\n",
    "                for k in range(batch_size):\n",
    "                    current_n = test_obs_mask[k].sum().item()\n",
    "                    plt.scatter(last_obs_vals[k, :current_n, :dx].cpu().numpy(), test_obs0[k, current_n, dx:].cpu().numpy(), label='Condition')\n",
    "                    plt.plot(test_tar_y[k, :, 0].cpu().numpy(), label=f\"Groundtruth\")\n",
    "                    plt.plot(pred0[k, :, 0].cpu().numpy(), label=f\"Prediction\")\n",
    "                    \n",
    "                    plt.legend(loc='upper left')\n",
    "                    plt.savefig(f'{img_folder}{epoch}_{test_traj_ids[j][k]}_bare.png')\n",
    "                    plt.clf()\n",
    "\n",
    "                    plt.scatter(last_obs_vals[k, :current_n, :dx].cpu().numpy(), test_obs1[k, current_n, dph:].cpu().numpy(), label='Condition')\n",
    "                    plt.plot(test_tar_y[k, :, 0].cpu().numpy(), label=f\"Groundtruth\")\n",
    "                    plt.plot(pred1[k, :, 0].cpu().numpy(), label=f\"Prediction\")\n",
    "                    \n",
    "                    plt.legend(loc='upper left')\n",
    "                    plt.savefig(f'{img_folder}{epoch}_{test_traj_ids[j][k]}_ph.png')\n",
    "                    plt.clf()\n",
    "\n",
    "                    plt.scatter(last_obs_vals[k, :current_n, :dx].cpu().numpy(), test_obs2[k, :current_n, dpe:].cpu().numpy(), label='Condition')\n",
    "                    plt.plot(test_tar_y[k, :, 0].cpu().numpy(), label=f\"Groundtruth\")\n",
    "                    plt.plot(pred2[k, :, 0].cpu().numpy(), label=f\"Prediction\")\n",
    "                    \n",
    "                    plt.legend(loc='upper left')\n",
    "                    plt.savefig(f'{img_folder}{epoch}_{test_traj_ids[j][k]}_pe.png')\n",
    "                    plt.clf()\n",
    "\n",
    "            test_loss0 += mse_loss(pred0[:, :, :m0.output_dim], test_tar_y).item()\n",
    "            test_loss1 += mse_loss(pred1[:, :, :m1.output_dim], test_tar_y).item()\n",
    "            test_loss2 += mse_loss(pred2[:, :, :m2.output_dim], test_tar_y).item()\n",
    "        \n",
    "        test_loss0 /= test_epoch_iter\n",
    "        test_loss1 /= test_epoch_iter\n",
    "        test_loss2 /= test_epoch_iter\n",
    "            \n",
    "        if test_loss0 < min_test_loss0:\n",
    "            min_test_loss0 = test_loss0\n",
    "            print(f'BARE New best: {min_test_loss0}, PH best: {min_test_loss1}, PE best: {min_test_loss2}')\n",
    "            torch.save(m0_.state_dict(), f'{root_folder}saved_models/bare.pt')\n",
    "\n",
    "        if test_loss1 < min_test_loss1:\n",
    "            min_test_loss1 = test_loss1\n",
    "            print(f'PH New best: {min_test_loss1}, PE best: {min_test_loss2}, BARE best: {min_test_loss0}')\n",
    "            torch.save(m1_.state_dict(), f'{root_folder}saved_models/ph.pt')\n",
    "\n",
    "        if test_loss2 < min_test_loss2:\n",
    "            min_test_loss2 = test_loss2\n",
    "            print(f'PE New best: {min_test_loss2}, BARE best: {min_test_loss0}, PH best: {min_test_loss1}')\n",
    "            torch.save(m2_.state_dict(), f'{root_folder}saved_models/lstm.pt')\n",
    "\n",
    "    epoch_loss0 /= epoch_iter\n",
    "    epoch_loss1 /= epoch_iter\n",
    "    epoch_loss2 /= epoch_iter\n",
    "\n",
    "    avg_loss0 += epoch_loss0\n",
    "    avg_loss1 += epoch_loss1\n",
    "    avg_loss2 += epoch_loss2\n",
    "\n",
    "    l0.append(epoch_loss0)\n",
    "    l1.append(epoch_loss1)\n",
    "    l2.append(epoch_loss2)\n",
    "\n",
    "    if epoch % loss_report_interval == 0:\n",
    "        print(\"Epoch: {}, Losses: BARE: {}, PH: {}, PE: {}\".format(epoch, avg_loss0/loss_report_interval, avg_loss1/loss_report_interval, avg_loss2/loss_report_interval))\n",
    "        avg_loss0, avg_loss1, avg_loss2 = 0, 0, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(l0, f'{root_folder}losses_bare.pt')\n",
    "torch.save(l1, f'{root_folder}losses_ph.pt')\n",
    "torch.save(l2, f'{root_folder}losses_pe.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
