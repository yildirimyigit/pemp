{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "folder_path = '../models/'\n",
    "if folder_path not in sys.path:\n",
    "    sys.path.append(folder_path)\n",
    "\n",
    "folder_path = '../data/'\n",
    "if folder_path not in sys.path:\n",
    "    sys.path.append(folder_path)\n",
    "\n",
    "from cnmp import CNMP\n",
    "from positional_encoders import *\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "def get_free_gpu():\n",
    "    gpu_util = []\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        torch.cuda.set_device(i)  # Switch GPU\n",
    "#        gpu_util.append((i, torch.cuda.memory_stats()['reserved_bytes.all.current'] / (1024 ** 2)))\n",
    "        gpu_util.append((i, torch.cuda.utilization()))\n",
    "    gpu_util.sort(key=lambda x: x[1])\n",
    "    return gpu_util[0][0]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    available_gpu = get_free_gpu()\n",
    "    if available_gpu == 0:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda:{available_gpu}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(\"Device :\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([8, 600, 1]), y_train shape: torch.Size([8, 600, 3]), g_train shape: torch.Size([8])\n",
      "x_test shape: torch.Size([2, 600, 1]), y_test shape: torch.Size([2, 600, 3]), g_test shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "dx, dy, dg, dph, dpe = 1, 3, 1, 0, 27\n",
    "num_demos, num_test = 8, 2\n",
    "num_trajs = num_demos + num_test\n",
    "t_steps = 600\n",
    "n_max, m_max = 60, 60\n",
    "\n",
    "trajectories, freqs = torch.from_numpy(np.load('../sim/data/hopper_interpolated_actions.npy')), torch.from_numpy(np.load('../sim/data/hopper_freqs.npy'))\n",
    "max_freq = max(freqs)\n",
    "\n",
    "perm_ids = torch.randperm(num_trajs)\n",
    "train_ids, test_ids = perm_ids[:num_demos], perm_ids[num_demos:]\n",
    "\n",
    "all_x = torch.linspace(0, 1, t_steps).unsqueeze(-1).unsqueeze(0).repeat(num_trajs,1,1)\n",
    "\n",
    "x_train, x_test = all_x[train_ids], all_x[test_ids]\n",
    "y_train, y_test = trajectories[train_ids], trajectories[test_ids]\n",
    "g_train, g_test = freqs[train_ids]/max_freq, freqs[test_ids]/max_freq\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}, g_train shape: {g_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}, g_test shape: {g_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = generate_positional_encoding(t_steps, dpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bare:  135174\n",
      "PE:  148486\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "\n",
    "enc_dims = [256,256]\n",
    "dec_dims = [256,256]\n",
    "\n",
    "m0_ = CNMP(input_dim=dx+dg, output_dim=dy, n_max=n_max, m_max=m_max, encoder_hidden_dims=enc_dims, decoder_hidden_dims=dec_dims, batch_size=batch_size, device=device)\n",
    "opt0 = torch.optim.Adam(lr=3e-4, params=m0_.parameters())\n",
    "\n",
    "m1_ = CNMP(input_dim=dpe+dg, output_dim=dy, n_max=n_max, m_max=m_max, encoder_hidden_dims=enc_dims, decoder_hidden_dims=dec_dims, batch_size=batch_size, device=device)\n",
    "opt1 = torch.optim.Adam(lr=3e-4, params=m1_.parameters())\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in m0_.parameters())\n",
    "print('Bare: ', pytorch_total_params)\n",
    "pytorch_total_params = sum(p.numel() for p in m1_.parameters())\n",
    "print('PE: ', pytorch_total_params)\n",
    "\n",
    "if torch.__version__ >= \"2.0\":\n",
    "    m0, m1 = torch.compile(m0_), torch.compile(m1_)\n",
    "else:\n",
    "    m0, m1 = m0_, m1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs0 = torch.zeros((batch_size, n_max, dx+dg+dy), dtype=torch.float32, device=device)\n",
    "tar_x0 = torch.zeros((batch_size, m_max, dx+dg), dtype=torch.float32, device=device)\n",
    "\n",
    "obs1 = torch.zeros((batch_size, n_max, dpe+dg+dy), dtype=torch.float32, device=device)\n",
    "tar_x1 = torch.zeros((batch_size, m_max, dpe+dg), dtype=torch.float32, device=device)\n",
    "\n",
    "tar_y = torch.zeros((batch_size, m_max, dy), dtype=torch.float32, device=device)\n",
    "obs_mask = torch.zeros((batch_size, n_max), dtype=torch.bool, device=device)\n",
    "tar_mask = torch.zeros((batch_size, m_max), dtype=torch.bool, device=device)\n",
    "\n",
    "def prepare_masked_batch(t: list, traj_ids: list):\n",
    "    global obs0, tar_x0, obs1, tar_x1, tar_y, obs_mask, tar_mask\n",
    "    obs0.fill_(0)\n",
    "    tar_x0.fill_(0)\n",
    "    obs1.fill_(0)\n",
    "    tar_x1.fill_(0)\n",
    "    tar_y.fill_(0)\n",
    "    obs_mask.fill_(False)\n",
    "    tar_mask.fill_(False)\n",
    "\n",
    "    for i, traj_id in enumerate(traj_ids):\n",
    "        traj = t[traj_id]\n",
    "\n",
    "        n = torch.randint(1, n_max+1, (1,)).item()\n",
    "        m = torch.randint(1, m_max+1, (1,)).item()\n",
    "\n",
    "        permuted_ids = torch.randperm(t_steps)\n",
    "        n_ids = permuted_ids[:n]\n",
    "        m_ids = permuted_ids[n:n+m]\n",
    "\n",
    "        obs0[i, :n, :dx] = x_train[traj_id, n_ids]  # t\n",
    "        obs0[i, :n, dx:dx+dg] = g_train[traj_id]  # gamma\n",
    "        obs0[i, :n, dx+dg:] = traj[n_ids]  # SM(t)\n",
    "\n",
    "        obs1[i, :n, :dpe] = pe[n_ids]  # PE(t)\n",
    "        obs1[i, :n, dpe:dpe+dg] = g_train[traj_id]  # gamma\n",
    "        obs1[i, :n, dpe+dg:] = traj[n_ids]  # SM(t)\n",
    "\n",
    "        obs_mask[i, :n] = True\n",
    "        \n",
    "        tar_x0[i, :m, :dx] = x_train[traj_id, m_ids]\n",
    "        tar_x0[i, :m, dx:] = g_train[traj_id]\n",
    "        tar_x1[i, :m, :dpe] = pe[m_ids]\n",
    "        tar_x1[i, :m, dpe:] = g_train[traj_id]        \n",
    "        \n",
    "        tar_y[i, :m] = traj[m_ids]\n",
    "        tar_mask[i, :m] = True\n",
    "\n",
    "\n",
    "test_obs0 = torch.zeros((batch_size, n_max, dx+dg+dy), dtype=torch.float32, device=device)\n",
    "test_tar_x0 = torch.zeros((batch_size, t_steps, dx+dg), dtype=torch.float32, device=device)\n",
    "\n",
    "test_obs1 = torch.zeros((batch_size, n_max, dpe+dg+dy), dtype=torch.float32, device=device)\n",
    "test_tar_x1 = torch.zeros((batch_size, t_steps, dpe+dg), dtype=torch.float32, device=device)\n",
    "\n",
    "test_tar_y = torch.zeros((batch_size, t_steps, dy), dtype=torch.float32, device=device)\n",
    "test_obs_mask = torch.zeros((batch_size, n_max), dtype=torch.bool, device=device)\n",
    "last_obs_vals = torch.zeros((batch_size, n_max, dx), dtype=torch.int32, device=device)  # only for plotting\n",
    "\n",
    "def prepare_masked_test_batch(t: list, traj_ids: list, fixed_ind=None):\n",
    "    global test_obs0, test_tar_x0, test_obs1, test_tar_x1, test_tar_y, test_obs_mask, last_obs_vals\n",
    "    test_obs0.fill_(0)\n",
    "    test_tar_x0.fill_(0)\n",
    "    test_obs1.fill_(0)\n",
    "    test_tar_x1.fill_(0)\n",
    "    test_tar_y.fill_(0)\n",
    "    test_obs_mask.fill_(False)\n",
    "    last_obs_vals.fill_(0)\n",
    "\n",
    "    for i, traj_id in enumerate(traj_ids):\n",
    "        traj = t[traj_id]\n",
    "\n",
    "        # n = num_peaks #torch.randint(5, n_max, (1,)).item()\n",
    "        n = torch.randint(1, n_max+1, (1,)).item()\n",
    "\n",
    "        permuted_ids = torch.randperm(t_steps)\n",
    "        n_ids = permuted_ids[:n]\n",
    "        m_ids = torch.arange(t_steps)\n",
    "\n",
    "        if fixed_ind != None:\n",
    "            for p in range(n):\n",
    "                n_ids[p] = fixed_ind[i, p]\n",
    "            # n_ids[-1] = fixed_ind[i]\n",
    "\n",
    "        test_obs0[i, :n, :dx] = x_test[traj_id, n_ids]  # t\n",
    "        test_obs0[i, :n, dx:dx+dg] = g_test[traj_id]\n",
    "        test_obs0[i, :n, dx+dg:] = traj[n_ids]  # SM(t)\n",
    "\n",
    "        test_obs1[i, :n, :dpe] = pe[n_ids]  # PE(t)\n",
    "        test_obs1[i, :n, dpe:dpe+dg] = g_test[traj_id]\n",
    "        test_obs1[i, :n, dpe+dg:] = traj[n_ids]\n",
    "\n",
    "        last_obs_vals[i, :n] = n_ids.unsqueeze(-1)\n",
    "        test_obs_mask[i, :n] = True\n",
    "        \n",
    "        test_tar_x0[i, :, :dx] = x_test[traj_id, m_ids]\n",
    "        test_tar_x1[i, :, :dpe] = pe[m_ids]\n",
    "\n",
    "        test_tar_y[i] = traj[m_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New BARE best: 0.4437295198440552, PE best: 1000000\n",
      "New PE best: 0.438871830701828, BARE best: 0.4437295198440552\n",
      "Epoch: 0, Losses: BARE: 0.001959403157234192, PE: 0.0019306052327156067\n",
      "Epoch: 500, Losses: BARE: 0.8399373095035553, PE: 0.6970482487455011\n",
      "New BARE best: 0.4434361159801483, PE best: 0.438871830701828\n",
      "Epoch: 1000, Losses: BARE: 0.8408923134803772, PE: 0.42782461030362173\n",
      "Epoch: 1500, Losses: BARE: 0.8354429938793182, PE: 0.2432000889768824\n",
      "New BARE best: 0.4433012008666992, PE best: 0.438871830701828\n",
      "New PE best: 0.4354000687599182, BARE best: 0.4433012008666992\n",
      "Epoch: 2000, Losses: BARE: 0.8330122887194157, PE: 0.18494774474599399\n",
      "Epoch: 2500, Losses: BARE: 0.8270865197479725, PE: 0.0620878695352003\n",
      "New BARE best: 0.43708741664886475, PE best: 0.4354000687599182\n",
      "New PE best: 0.41785719990730286, BARE best: 0.43708741664886475\n",
      "Epoch: 3000, Losses: BARE: 0.8174449216723442, PE: 0.031171181712998076\n",
      "Epoch: 3500, Losses: BARE: 0.8118214184045791, PE: -0.031040510441642254\n",
      "New PE best: 0.4025043547153473, BARE best: 0.43708741664886475\n",
      "Epoch: 4000, Losses: BARE: 0.8013363698869944, PE: -0.075497398275882\n",
      "Epoch: 4500, Losses: BARE: 0.7914039018899203, PE: -0.11056209720578045\n",
      "New PE best: 0.3923560380935669, BARE best: 0.43708741664886475\n",
      "Epoch: 5000, Losses: BARE: 0.78538150203228, PE: -0.17933054856583477\n",
      "Epoch: 5500, Losses: BARE: 0.7743934441655874, PE: -0.19424224813235924\n",
      "New PE best: 0.38586291670799255, BARE best: 0.43708741664886475\n",
      "Epoch: 6000, Losses: BARE: 0.7765630296170711, PE: -0.23667320045386442\n",
      "Epoch: 6500, Losses: BARE: 0.7652230686694383, PE: -0.2556736218233127\n",
      "Epoch: 7000, Losses: BARE: 0.7674749826788902, PE: -0.19302117573004215\n",
      "Epoch: 7500, Losses: BARE: 0.7628070302605628, PE: -0.2605818110315595\n",
      "Epoch: 8000, Losses: BARE: 0.7575883136093616, PE: -0.3079160006660968\n",
      "Epoch: 8500, Losses: BARE: 0.7563746048808098, PE: -0.33965196875017134\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "timestamp = int(time.time())\n",
    "root_folder = f'../outputs/comparison/mind_change/sim/bare_pe/{str(timestamp)}/'\n",
    "\n",
    "if not os.path.exists(root_folder):\n",
    "    os.makedirs(root_folder)\n",
    "\n",
    "if not os.path.exists(f'{root_folder}saved_models/'):\n",
    "    os.makedirs(f'{root_folder}saved_models/')\n",
    "\n",
    "img_folder = f'{root_folder}img/'\n",
    "if not os.path.exists(img_folder):\n",
    "    os.makedirs(img_folder)\n",
    "\n",
    "torch.save(y_train, f'{root_folder}y.pt')\n",
    "\n",
    "\n",
    "epochs = 1_000_000\n",
    "epoch_iter = num_demos // batch_size\n",
    "test_epoch_iter = num_test//batch_size\n",
    "avg_loss0, avg_loss1 = 0, 0\n",
    "loss_report_interval = 500\n",
    "test_per_epoch = 1000\n",
    "min_test_loss0, min_test_loss1 = 1000000, 1000000\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "plot_test = True\n",
    "\n",
    "l0, l1, l2, l3 = [], [], [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss0, epoch_loss1 = 0, 0\n",
    "\n",
    "    traj_ids = torch.randperm(num_demos)[:batch_size * epoch_iter].chunk(epoch_iter)\n",
    "\n",
    "    for i in range(epoch_iter):\n",
    "        prepare_masked_batch(y_train, traj_ids[i])\n",
    "\n",
    "        opt0.zero_grad()\n",
    "        pred0 = m0(obs0, tar_x0, obs_mask)\n",
    "        loss0 = m0.loss(pred0, tar_y, tar_mask)\n",
    "        loss0.backward()\n",
    "        opt0.step()\n",
    "\n",
    "        epoch_loss0 += loss0.item()\n",
    "\n",
    "\n",
    "        opt1.zero_grad()\n",
    "        pred1 = m1(obs1, tar_x1, obs_mask)\n",
    "        loss1 = m1.loss(pred1, tar_y, tar_mask)\n",
    "        loss1.backward()\n",
    "        opt1.step()\n",
    "\n",
    "        epoch_loss1 += loss1.item()\n",
    "\n",
    "\n",
    "    if epoch % test_per_epoch == 0:# and epoch > 0:\n",
    "        test_traj_ids = torch.randperm(num_test)[:batch_size*test_epoch_iter].chunk(test_epoch_iter)\n",
    "        test_loss0, test_loss1 = 0, 0\n",
    "\n",
    "        for j in range(test_epoch_iter):\n",
    "            prepare_masked_test_batch(y_test, test_traj_ids[j])\n",
    "\n",
    "            pred0 = m0.val(test_obs0, test_tar_x0, test_obs_mask)\n",
    "            pred1 = m1.val(test_obs1, test_tar_x1, test_obs_mask)\n",
    "            \n",
    "            # TODO: dy > 1\n",
    "            # if plot_test:\n",
    "            #     for k in range(batch_size):\n",
    "            #         current_n = test_obs_mask[k].sum().item()\n",
    "            #         plt.scatter(last_obs_vals[k, :current_n, :dx].cpu().numpy(), test_obs0[k, :current_n, dx+dg:].cpu().numpy(), label='Condition')\n",
    "            #         plt.plot(test_tar_y[k, :, 0].cpu().numpy(), label=f\"Groundtruth\")\n",
    "            #         plt.plot(pred0[k, :, 0].cpu().numpy(), label=f\"Prediction\")\n",
    "                    \n",
    "            #         plt.legend(loc='upper left')\n",
    "            #         plt.title(f'Epoch: {epoch}', fontsize=20)\n",
    "            #         plt.savefig(f'{img_folder}{epoch}_{test_traj_ids[j][k]}_bare.png')\n",
    "            #         plt.clf()\n",
    "\n",
    "            #         plt.scatter(last_obs_vals[k, :current_n, :dx].cpu().numpy(), test_obs1[k, :current_n, dpe+dg:].cpu().numpy(), label='Condition')\n",
    "            #         plt.plot(test_tar_y[k, :, 0].cpu().numpy(), label=f\"Groundtruth\")\n",
    "            #         plt.plot(pred1[k, :, 0].cpu().numpy(), label=f\"Prediction\")\n",
    "                    \n",
    "            #         plt.legend(loc='upper left')\n",
    "            #         plt.title(f'Epoch: {epoch}', fontsize=20)\n",
    "            #         plt.savefig(f'{img_folder}{epoch}_{test_traj_ids[j][k]}_ph.png')\n",
    "            #         plt.clf()\n",
    "                    \n",
    "\n",
    "            test_loss0 += mse_loss(pred0[:, :, :m0.output_dim], test_tar_y).item()\n",
    "            test_loss1 += mse_loss(pred1[:, :, :m1.output_dim], test_tar_y).item()\n",
    "        \n",
    "        test_loss0 /= test_epoch_iter\n",
    "        test_loss1 /= test_epoch_iter\n",
    "            \n",
    "        if test_loss0 < min_test_loss0:\n",
    "            min_test_loss0 = test_loss0\n",
    "            print(f'New BARE best: {min_test_loss0}, PE best: {min_test_loss1}')\n",
    "            torch.save(m0_.state_dict(), f'{root_folder}saved_models/bare.pt')\n",
    "\n",
    "        if test_loss1 < min_test_loss1:\n",
    "            min_test_loss1 = test_loss1\n",
    "            print(f'New PE best: {min_test_loss1}, BARE best: {min_test_loss0}')\n",
    "            torch.save(m1_.state_dict(), f'{root_folder}saved_models/pe.pt')\n",
    "\n",
    "\n",
    "    epoch_loss0 /= epoch_iter\n",
    "    epoch_loss1 /= epoch_iter\n",
    "\n",
    "    avg_loss0 += epoch_loss0\n",
    "    avg_loss1 += epoch_loss1\n",
    "\n",
    "    l0.append(epoch_loss0)\n",
    "    l1.append(epoch_loss1)\n",
    "\n",
    "    if epoch % loss_report_interval == 0:\n",
    "        print(\"Epoch: {}, Losses: BARE: {}, PE: {}\".format(epoch, avg_loss0/loss_report_interval, avg_loss1/loss_report_interval))\n",
    "        avg_loss0, avg_loss1 = 0, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last_obs_vals.shape\n",
    "test_obs0[k, current_n, dx:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(l0, f'{root_folder}losses_bare.pt')\n",
    "torch.save(l1, f'{root_folder}losses_pe.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
